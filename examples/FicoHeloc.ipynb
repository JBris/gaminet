{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:27:03.147769Z",
     "start_time": "2021-10-14T12:26:59.994571Z"
    },
    "executionInfo": {
     "elapsed": 13684,
     "status": "ok",
     "timestamp": 1603961888588,
     "user": {
      "displayName": "Aijun Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhBWtj1H5SEwpPrXe9cpeI6ygPRrtmqnla1B8Q5cg=s64",
      "userId": "04897292400908543781"
     },
     "user_tz": -480
    },
    "id": "b4v3-n4OAq4b"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler\n",
    "\n",
    "from gaminet import GAMINet\n",
    "from gaminet.utils import local_visualize\n",
    "from gaminet.utils import global_visualize_density\n",
    "from gaminet.utils import global_visualize_wo_density\n",
    "from gaminet.utils import feature_importance_visualize\n",
    "from gaminet.utils import plot_regularization\n",
    "from gaminet.utils import plot_trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:27:03.165154Z",
     "start_time": "2021-10-14T12:27:03.150374Z"
    },
    "executionInfo": {
     "elapsed": 13674,
     "status": "ok",
     "timestamp": 1603961888590,
     "user": {
      "displayName": "Aijun Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhBWtj1H5SEwpPrXe9cpeI6ygPRrtmqnla1B8Q5cg=s64",
      "userId": "04897292400908543781"
     },
     "user_tz": -480
    },
    "id": "NxvU955j9HxO"
   },
   "outputs": [],
   "source": [
    "def load_fico(path=\"./\", missing_strategy=\"drop\"):\n",
    "    data = pd.read_csv(path + \"/fico/heloc_dataset_v1.csv\")\n",
    "    meta_info = json.load(open(path + \"/fico/data_types.json\"))\n",
    "    meta_info.pop(\"RiskPerformance\")\n",
    "\n",
    "    ## remove samples with all the values == -9\n",
    "    rem_sample_idx = np.where(np.sum(data.values[:, 1:].astype(float) == -9, 1) == 23)[0]\n",
    "    keep_sample_idx = np.where(np.sum(data.values[:, 1:].astype(float) == -9, 1) < 23)[0]\n",
    "    data_rem9 = data.iloc[keep_sample_idx]\n",
    "\n",
    "    ## dummy for -7, -8, -9\n",
    "    sample_size = data_rem9.shape[0]\n",
    "    dummy_data = pd.DataFrame(index = data_rem9.index)\n",
    "    for i in np.where(np.sum(data_rem9 == -9, 0).values > 0)[0]:\n",
    "        temp = np.zeros(sample_size)\n",
    "        temp[np.where(data_rem9.iloc[:, i].values == -9)[0]] = 1\n",
    "        dummy_data[data_rem9.columns[i] + \"_D-9\"] = temp\n",
    "        meta_info.update({data_rem9.columns[i] + \"_D-9\":{\"type\": \"categorical\"}})\n",
    "\n",
    "    for i in np.where(np.sum(data_rem9 == -8, 0).values > 0)[0]:\n",
    "        temp = np.zeros(sample_size)\n",
    "        temp[np.where(data_rem9.iloc[:, i].values == -8)[0]] = 1\n",
    "        dummy_data[data_rem9.columns[i] + \"_D-8\"] = temp\n",
    "        meta_info.update({data_rem9.columns[i] + \"_D-8\":{\"type\": \"categorical\"}})\n",
    "\n",
    "    for i in np.where(np.sum(data_rem9 == -7, 0).values > 0)[0]:\n",
    "        temp = np.zeros(sample_size)\n",
    "        temp[np.where(data_rem9.iloc[:, i].values == -7)[0]] = 1\n",
    "        dummy_data[data_rem9.columns[i] + \"_D-7\"] = temp\n",
    "        meta_info.update({data_rem9.columns[i] + \"_D-7\":{\"type\": \"categorical\"}})\n",
    "\n",
    "    meta_info.update({\"RiskPerformance\":{\"type\": \"target\"}})\n",
    "    final_data = pd.concat([data_rem9.replace(-9, 0).replace(-8, 0).replace(-7, 0), dummy_data], 1)\n",
    "    x, y = final_data.iloc[:,1:].values, final_data.iloc[:,[0]].values\n",
    "    return x, y, \"Classification\", meta_info\n",
    "\n",
    "def load_classification_data(name):\n",
    "    data_path = '.'\n",
    "    func_dict = {'fico':load_fico}\n",
    "    def wrapper(random_state):\n",
    "        function_name_ = func_dict[name]\n",
    "        x, y, task_type, meta_info = function_name_(data_path, missing_strategy=\"impute\")\n",
    "        xx = np.zeros((x.shape[0], x.shape[1]), dtype=np.float32)\n",
    "        for i, (key, item) in enumerate(meta_info.items()):\n",
    "            if item['type'] == 'target':\n",
    "                enc = OrdinalEncoder()\n",
    "                enc.fit(y)\n",
    "                y = enc.transform(y)\n",
    "                meta_info[key]['values'] = enc.categories_[0].tolist()\n",
    "            elif item['type'] == 'categorical':\n",
    "                enc = OrdinalEncoder()\n",
    "                xx[:,[i]] = enc.fit_transform(x[:,[i]])\n",
    "                meta_info[key]['values'] = []\n",
    "                for item in enc.categories_[0].tolist():\n",
    "                    try:\n",
    "                        if item == int(item):\n",
    "                            meta_info[key]['values'].append(str(int(item)))\n",
    "                        else:\n",
    "                            meta_info[key]['values'].append(str(item))\n",
    "                    except ValueError:\n",
    "                        meta_info[key]['values'].append(str(item))\n",
    "            else:\n",
    "                sx = MinMaxScaler((0, 1))\n",
    "                xx[:,[i]] = sx.fit_transform(x[:,[i]])\n",
    "                meta_info[key]['scaler'] = sx\n",
    "        train_x, test_x, train_y, test_y = train_test_split(xx.astype(np.float32), y, stratify=y,\n",
    "                                                            test_size=0.2, random_state=random_state)\n",
    "        return train_x, test_x, train_y, test_y, task_type, meta_info\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:27:03.171008Z",
     "start_time": "2021-10-14T12:27:03.167380Z"
    }
   },
   "outputs": [],
   "source": [
    "def metric_wrapper(metric, scaler):\n",
    "    def wrapper(label, pred):\n",
    "        return metric(label, pred, scaler=scaler)\n",
    "    return wrapper\n",
    "\n",
    "def auc(label, pred, scaler=None):\n",
    "    return roc_auc_score(label, pred)\n",
    "\n",
    "get_metric = metric_wrapper(auc, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:27:03.284944Z",
     "start_time": "2021-10-14T12:27:03.172746Z"
    },
    "executionInfo": {
     "elapsed": 13662,
     "status": "ok",
     "timestamp": 1603961888591,
     "user": {
      "displayName": "Aijun Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhBWtj1H5SEwpPrXe9cpeI6ygPRrtmqnla1B8Q5cg=s64",
      "userId": "04897292400908543781"
     },
     "user_tz": -480
    },
    "id": "gGPEeEbL9HxR"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/r7user1/anaconda2_local/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:33: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n"
     ]
    }
   ],
   "source": [
    "random_state = 0\n",
    "data_loader = load_classification_data(\"fico\")\n",
    "train_x, test_x, train_y, test_y, task_type, meta_info = data_loader(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:27:03.293338Z",
     "start_time": "2021-10-14T12:27:03.286946Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ExternalRiskEstimate', 'MSinceOldestTradeOpen', 'MSinceMostRecentTradeOpen', 'AverageMInFile', 'NumSatisfactoryTrades', 'NumTrades60Ever2DerogPubRec', 'NumTrades90Ever2DerogPubRec', 'PercentTradesNeverDelq', 'MSinceMostRecentDelq', 'MaxDelq2PublicRecLast12M', 'MaxDelqEver', 'NumTotalTrades', 'NumTradesOpeninLast12M', 'PercentInstallTrades', 'MSinceMostRecentInqexcl7days', 'NumInqLast6M', 'NumInqLast6Mexcl7days', 'NetFractionRevolvingBurden', 'NetFractionInstallBurden', 'NumRevolvingTradesWBalance', 'NumInstallTradesWBalance', 'NumBank2NatlTradesWHighUtilization', 'PercentTradesWBalance', 'ExternalRiskEstimate_D-9', 'MSinceOldestTradeOpen_D-8', 'MSinceMostRecentDelq_D-8', 'MSinceMostRecentInqexcl7days_D-8', 'NetFractionRevolvingBurden_D-8', 'NetFractionInstallBurden_D-8', 'NumRevolvingTradesWBalance_D-8', 'NumInstallTradesWBalance_D-8', 'NumBank2NatlTradesWHighUtilization_D-8', 'PercentTradesWBalance_D-8', 'MSinceMostRecentDelq_D-7', 'MSinceMostRecentInqexcl7days_D-7', 'RiskPerformance'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_info.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:28:22.466301Z",
     "start_time": "2021-10-14T12:27:03.296287Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################GAMI-Net training start.####################\n",
      "##########Stage 1: main effect training start.##########\n",
      "Main effects training epoch: 1, train loss: 0.66998, val loss: 0.66963\n",
      "Main effects training epoch: 2, train loss: 0.66190, val loss: 0.66130\n",
      "Main effects training epoch: 3, train loss: 0.64706, val loss: 0.64622\n",
      "Main effects training epoch: 4, train loss: 0.63021, val loss: 0.62934\n",
      "Main effects training epoch: 5, train loss: 0.61746, val loss: 0.61660\n",
      "Main effects training epoch: 6, train loss: 0.60676, val loss: 0.60453\n",
      "Main effects training epoch: 7, train loss: 0.60154, val loss: 0.59967\n",
      "Main effects training epoch: 8, train loss: 0.59475, val loss: 0.59266\n",
      "Main effects training epoch: 9, train loss: 0.58917, val loss: 0.58660\n",
      "Main effects training epoch: 10, train loss: 0.58294, val loss: 0.58000\n",
      "Main effects training epoch: 11, train loss: 0.57726, val loss: 0.57405\n",
      "Main effects training epoch: 12, train loss: 0.57232, val loss: 0.56839\n",
      "Main effects training epoch: 13, train loss: 0.56903, val loss: 0.56568\n",
      "Main effects training epoch: 14, train loss: 0.56421, val loss: 0.56099\n",
      "Main effects training epoch: 15, train loss: 0.56053, val loss: 0.55769\n",
      "Main effects training epoch: 16, train loss: 0.55800, val loss: 0.55547\n",
      "Main effects training epoch: 17, train loss: 0.55527, val loss: 0.55245\n",
      "Main effects training epoch: 18, train loss: 0.55215, val loss: 0.55044\n",
      "Main effects training epoch: 19, train loss: 0.55032, val loss: 0.54869\n",
      "Main effects training epoch: 20, train loss: 0.54857, val loss: 0.54734\n",
      "Main effects training epoch: 21, train loss: 0.54690, val loss: 0.54630\n",
      "Main effects training epoch: 22, train loss: 0.54606, val loss: 0.54533\n",
      "Main effects training epoch: 23, train loss: 0.54340, val loss: 0.54310\n",
      "Main effects training epoch: 24, train loss: 0.54345, val loss: 0.54332\n",
      "Main effects training epoch: 25, train loss: 0.54089, val loss: 0.54090\n",
      "Main effects training epoch: 26, train loss: 0.54058, val loss: 0.54130\n",
      "Main effects training epoch: 27, train loss: 0.53904, val loss: 0.53965\n",
      "Main effects training epoch: 28, train loss: 0.53846, val loss: 0.53952\n",
      "Main effects training epoch: 29, train loss: 0.53861, val loss: 0.54010\n",
      "Main effects training epoch: 30, train loss: 0.53705, val loss: 0.53834\n",
      "Main effects training epoch: 31, train loss: 0.53741, val loss: 0.53903\n",
      "Main effects training epoch: 32, train loss: 0.53997, val loss: 0.54132\n",
      "Main effects training epoch: 33, train loss: 0.53555, val loss: 0.53745\n",
      "Main effects training epoch: 34, train loss: 0.53519, val loss: 0.53699\n",
      "Main effects training epoch: 35, train loss: 0.53502, val loss: 0.53692\n",
      "Main effects training epoch: 36, train loss: 0.53572, val loss: 0.53750\n",
      "Main effects training epoch: 37, train loss: 0.53419, val loss: 0.53645\n",
      "Main effects training epoch: 38, train loss: 0.53437, val loss: 0.53689\n",
      "Main effects training epoch: 39, train loss: 0.53396, val loss: 0.53642\n",
      "Main effects training epoch: 40, train loss: 0.53337, val loss: 0.53596\n",
      "Main effects training epoch: 41, train loss: 0.53573, val loss: 0.53821\n",
      "Main effects training epoch: 42, train loss: 0.53301, val loss: 0.53566\n",
      "Main effects training epoch: 43, train loss: 0.53276, val loss: 0.53556\n",
      "Main effects training epoch: 44, train loss: 0.53352, val loss: 0.53629\n",
      "Main effects training epoch: 45, train loss: 0.53238, val loss: 0.53536\n",
      "Main effects training epoch: 46, train loss: 0.53393, val loss: 0.53663\n",
      "Main effects training epoch: 47, train loss: 0.53272, val loss: 0.53608\n",
      "Main effects training epoch: 48, train loss: 0.53290, val loss: 0.53632\n",
      "Main effects training epoch: 49, train loss: 0.53191, val loss: 0.53530\n",
      "Main effects training epoch: 50, train loss: 0.53339, val loss: 0.53649\n",
      "Main effects training epoch: 51, train loss: 0.53416, val loss: 0.53714\n",
      "Main effects training epoch: 52, train loss: 0.53203, val loss: 0.53551\n",
      "Main effects training epoch: 53, train loss: 0.53134, val loss: 0.53493\n",
      "Main effects training epoch: 54, train loss: 0.53149, val loss: 0.53495\n",
      "Main effects training epoch: 55, train loss: 0.53118, val loss: 0.53444\n",
      "Main effects training epoch: 56, train loss: 0.53173, val loss: 0.53549\n",
      "Main effects training epoch: 57, train loss: 0.53159, val loss: 0.53513\n",
      "Main effects training epoch: 58, train loss: 0.53110, val loss: 0.53464\n",
      "Main effects training epoch: 59, train loss: 0.53096, val loss: 0.53465\n",
      "Main effects training epoch: 60, train loss: 0.53496, val loss: 0.53892\n",
      "Main effects training epoch: 61, train loss: 0.53198, val loss: 0.53565\n",
      "Main effects training epoch: 62, train loss: 0.53064, val loss: 0.53452\n",
      "Main effects training epoch: 63, train loss: 0.53068, val loss: 0.53443\n",
      "Main effects training epoch: 64, train loss: 0.53070, val loss: 0.53442\n",
      "Main effects training epoch: 65, train loss: 0.53067, val loss: 0.53488\n",
      "Main effects training epoch: 66, train loss: 0.53180, val loss: 0.53531\n",
      "Main effects training epoch: 67, train loss: 0.53057, val loss: 0.53450\n",
      "Main effects training epoch: 68, train loss: 0.53079, val loss: 0.53467\n",
      "Main effects training epoch: 69, train loss: 0.53036, val loss: 0.53458\n",
      "Main effects training epoch: 70, train loss: 0.53051, val loss: 0.53442\n",
      "Main effects training epoch: 71, train loss: 0.53025, val loss: 0.53446\n",
      "Main effects training epoch: 72, train loss: 0.53064, val loss: 0.53466\n",
      "Main effects training epoch: 73, train loss: 0.53040, val loss: 0.53454\n",
      "Main effects training epoch: 74, train loss: 0.53418, val loss: 0.53790\n",
      "Main effects training epoch: 75, train loss: 0.53087, val loss: 0.53525\n",
      "Main effects training epoch: 76, train loss: 0.53073, val loss: 0.53485\n",
      "Main effects training epoch: 77, train loss: 0.53036, val loss: 0.53476\n",
      "Main effects training epoch: 78, train loss: 0.53015, val loss: 0.53469\n",
      "Main effects training epoch: 79, train loss: 0.53000, val loss: 0.53441\n",
      "Main effects training epoch: 80, train loss: 0.53009, val loss: 0.53445\n",
      "Main effects training epoch: 81, train loss: 0.53006, val loss: 0.53435\n",
      "Main effects training epoch: 82, train loss: 0.53029, val loss: 0.53483\n",
      "Main effects training epoch: 83, train loss: 0.53052, val loss: 0.53474\n",
      "Main effects training epoch: 84, train loss: 0.53042, val loss: 0.53521\n",
      "Main effects training epoch: 85, train loss: 0.53003, val loss: 0.53456\n",
      "Main effects training epoch: 86, train loss: 0.53233, val loss: 0.53661\n",
      "Main effects training epoch: 87, train loss: 0.53010, val loss: 0.53510\n",
      "Main effects training epoch: 88, train loss: 0.53196, val loss: 0.53621\n",
      "Main effects training epoch: 89, train loss: 0.52973, val loss: 0.53445\n",
      "Main effects training epoch: 90, train loss: 0.53133, val loss: 0.53617\n",
      "Main effects training epoch: 91, train loss: 0.53016, val loss: 0.53468\n",
      "Main effects training epoch: 92, train loss: 0.53025, val loss: 0.53543\n",
      "Main effects training epoch: 93, train loss: 0.52980, val loss: 0.53465\n",
      "Main effects training epoch: 94, train loss: 0.53016, val loss: 0.53517\n",
      "Main effects training epoch: 95, train loss: 0.52954, val loss: 0.53433\n",
      "Main effects training epoch: 96, train loss: 0.53072, val loss: 0.53538\n",
      "Main effects training epoch: 97, train loss: 0.53097, val loss: 0.53611\n",
      "Main effects training epoch: 98, train loss: 0.53065, val loss: 0.53533\n",
      "Main effects training epoch: 99, train loss: 0.52983, val loss: 0.53460\n",
      "Main effects training epoch: 100, train loss: 0.52942, val loss: 0.53402\n",
      "Main effects training epoch: 101, train loss: 0.53094, val loss: 0.53544\n",
      "Main effects training epoch: 102, train loss: 0.52943, val loss: 0.53425\n",
      "Main effects training epoch: 103, train loss: 0.52953, val loss: 0.53461\n",
      "Main effects training epoch: 104, train loss: 0.53067, val loss: 0.53574\n",
      "Main effects training epoch: 105, train loss: 0.53056, val loss: 0.53519\n",
      "Main effects training epoch: 106, train loss: 0.52991, val loss: 0.53537\n",
      "Main effects training epoch: 107, train loss: 0.52977, val loss: 0.53479\n",
      "Main effects training epoch: 108, train loss: 0.52940, val loss: 0.53446\n",
      "Main effects training epoch: 109, train loss: 0.52998, val loss: 0.53545\n",
      "Main effects training epoch: 110, train loss: 0.52924, val loss: 0.53424\n",
      "Main effects training epoch: 111, train loss: 0.52932, val loss: 0.53476\n",
      "Main effects training epoch: 112, train loss: 0.53013, val loss: 0.53557\n",
      "Main effects training epoch: 113, train loss: 0.52937, val loss: 0.53494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main effects training epoch: 114, train loss: 0.52961, val loss: 0.53513\n",
      "Main effects training epoch: 115, train loss: 0.52903, val loss: 0.53442\n",
      "Main effects training epoch: 116, train loss: 0.53156, val loss: 0.53662\n",
      "Main effects training epoch: 117, train loss: 0.52919, val loss: 0.53491\n",
      "Main effects training epoch: 118, train loss: 0.52972, val loss: 0.53545\n",
      "Main effects training epoch: 119, train loss: 0.52919, val loss: 0.53451\n",
      "Main effects training epoch: 120, train loss: 0.52932, val loss: 0.53503\n",
      "Main effects training epoch: 121, train loss: 0.53050, val loss: 0.53561\n",
      "Main effects training epoch: 122, train loss: 0.53262, val loss: 0.53772\n",
      "Main effects training epoch: 123, train loss: 0.53051, val loss: 0.53640\n",
      "Main effects training epoch: 124, train loss: 0.52919, val loss: 0.53455\n",
      "Main effects training epoch: 125, train loss: 0.52898, val loss: 0.53410\n",
      "Main effects training epoch: 126, train loss: 0.53172, val loss: 0.53788\n",
      "Main effects training epoch: 127, train loss: 0.52911, val loss: 0.53398\n",
      "Main effects training epoch: 128, train loss: 0.52896, val loss: 0.53476\n",
      "Main effects training epoch: 129, train loss: 0.53023, val loss: 0.53556\n",
      "Main effects training epoch: 130, train loss: 0.52902, val loss: 0.53454\n",
      "Main effects training epoch: 131, train loss: 0.52881, val loss: 0.53451\n",
      "Main effects training epoch: 132, train loss: 0.52890, val loss: 0.53473\n",
      "Main effects training epoch: 133, train loss: 0.53070, val loss: 0.53592\n",
      "Main effects training epoch: 134, train loss: 0.53045, val loss: 0.53603\n",
      "Main effects training epoch: 135, train loss: 0.52876, val loss: 0.53484\n",
      "Main effects training epoch: 136, train loss: 0.52892, val loss: 0.53452\n",
      "Main effects training epoch: 137, train loss: 0.52885, val loss: 0.53471\n",
      "Main effects training epoch: 138, train loss: 0.52867, val loss: 0.53452\n",
      "Main effects training epoch: 139, train loss: 0.52909, val loss: 0.53493\n",
      "Main effects training epoch: 140, train loss: 0.52912, val loss: 0.53456\n",
      "Main effects training epoch: 141, train loss: 0.52975, val loss: 0.53612\n",
      "Main effects training epoch: 142, train loss: 0.52868, val loss: 0.53426\n",
      "Main effects training epoch: 143, train loss: 0.52873, val loss: 0.53495\n",
      "Main effects training epoch: 144, train loss: 0.52886, val loss: 0.53473\n",
      "Main effects training epoch: 145, train loss: 0.52880, val loss: 0.53489\n",
      "Main effects training epoch: 146, train loss: 0.52852, val loss: 0.53467\n",
      "Main effects training epoch: 147, train loss: 0.52926, val loss: 0.53583\n",
      "Main effects training epoch: 148, train loss: 0.53030, val loss: 0.53583\n",
      "Main effects training epoch: 149, train loss: 0.52948, val loss: 0.53561\n",
      "Main effects training epoch: 150, train loss: 0.53233, val loss: 0.53888\n",
      "Main effects training epoch: 151, train loss: 0.53162, val loss: 0.53808\n",
      "Main effects training epoch: 152, train loss: 0.52846, val loss: 0.53448\n",
      "Main effects training epoch: 153, train loss: 0.52881, val loss: 0.53458\n",
      "Main effects training epoch: 154, train loss: 0.52867, val loss: 0.53478\n",
      "Main effects training epoch: 155, train loss: 0.53127, val loss: 0.53689\n",
      "Main effects training epoch: 156, train loss: 0.52863, val loss: 0.53483\n",
      "Main effects training epoch: 157, train loss: 0.52976, val loss: 0.53604\n",
      "Main effects training epoch: 158, train loss: 0.53675, val loss: 0.54229\n",
      "Main effects training epoch: 159, train loss: 0.52939, val loss: 0.53586\n",
      "Main effects training epoch: 160, train loss: 0.52853, val loss: 0.53462\n",
      "Main effects training epoch: 161, train loss: 0.52853, val loss: 0.53448\n",
      "Main effects training epoch: 162, train loss: 0.52867, val loss: 0.53514\n",
      "Main effects training epoch: 163, train loss: 0.52902, val loss: 0.53540\n",
      "Main effects training epoch: 164, train loss: 0.52832, val loss: 0.53454\n",
      "Main effects training epoch: 165, train loss: 0.52931, val loss: 0.53589\n",
      "Main effects training epoch: 166, train loss: 0.53032, val loss: 0.53696\n",
      "Main effects training epoch: 167, train loss: 0.52868, val loss: 0.53501\n",
      "Main effects training epoch: 168, train loss: 0.52875, val loss: 0.53452\n",
      "Main effects training epoch: 169, train loss: 0.52848, val loss: 0.53497\n",
      "Main effects training epoch: 170, train loss: 0.52833, val loss: 0.53430\n",
      "Main effects training epoch: 171, train loss: 0.52894, val loss: 0.53463\n",
      "Main effects training epoch: 172, train loss: 0.52835, val loss: 0.53451\n",
      "Main effects training epoch: 173, train loss: 0.52842, val loss: 0.53501\n",
      "Main effects training epoch: 174, train loss: 0.52969, val loss: 0.53597\n",
      "Main effects training epoch: 175, train loss: 0.52871, val loss: 0.53482\n",
      "Main effects training epoch: 176, train loss: 0.52839, val loss: 0.53471\n",
      "Main effects training epoch: 177, train loss: 0.53037, val loss: 0.53701\n",
      "Main effects training epoch: 178, train loss: 0.52957, val loss: 0.53615\n",
      "Early stop at epoch 178, with validation loss: 0.53615\n",
      "##########Stage 1: main effect training stop.##########\n",
      "##########Stage 2: interaction training start.##########\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'monotonicity' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-9b41c96c99c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mconvex_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             verbose=True, val_ratio=0.2, random_state=0)\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmodel_fico\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mdata_dict_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_fico\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mplot_trajectory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dict_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"fico_traj\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_png\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_eps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2_local/envs/py37/lib/python3.7/site-packages/gaminet/gaminet.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_x, train_y, sample_weight)\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"#\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"Stage 2: interaction training start.\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"#\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_interaction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    643\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_bp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_interaction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2_local/envs/py37/lib/python3.7/site-packages/gaminet/gaminet.py\u001b[0m in \u001b[0;36madd_interaction\u001b[0;34m(self, tr_x, tr_y, val_x, val_y, sample_weight)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteraction_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minteraction_list_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteract_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteract_num_added\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteraction_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteract_blocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_interaction_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteraction_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_interaction_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteraction_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2_local/envs/py37/lib/python3.7/site-packages/gaminet/layers.py\u001b[0m in \u001b[0;36mset_interaction_list\u001b[0;34m(self, interaction_list)\u001b[0m\n\u001b[1;32m    470\u001b[0m                                           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m                                           interact_id=i)\n\u001b[0;32m--> 472\u001b[0;31m             \u001b[0minteract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_interaction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minteraction_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteracts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minteract\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2_local/envs/py37/lib/python3.7/site-packages/gaminet/layers.py\u001b[0m in \u001b[0;36mset_interaction\u001b[0;34m(self, interaction)\u001b[0m\n\u001b[1;32m    319\u001b[0m                                             output_min=0.0, output_max=self.lattice_size[0] - 1.0)\n\u001b[1;32m    320\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonicity\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlattice_layer_input1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonicity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmonotonicity\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvexity\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlattice_layer_input1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvexity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvexity\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'monotonicity' is not defined"
     ]
    }
   ],
   "source": [
    "folder = \"./results/\"\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "\n",
    "\n",
    "model_fico = GAMINet(meta_info={\"X\" + str(i + 1):item for i, item in enumerate(meta_info.values())}, interact_num=20,\n",
    "            interact_arch=[40] * 5, subnet_arch=[40] * 5, \n",
    "            batch_size=200, task_type=task_type, activation_func=tf.nn.relu, \n",
    "            main_effect_epochs=5000, interaction_epochs=5000, tuning_epochs=500, \n",
    "            lr_bp=[0.001, 0.001, 0.0001], early_stop_thres=[50, 50, 50],\n",
    "            heredity=True, loss_threshold=0.0, reg_clarity=0.1,\n",
    "            mono_increasing_list=[0, 1, 2, 3, 4, 7, 8, 9, 10, 14],\n",
    "            mono_decreasing_list=[5, 6, 12, 15, 16, 17, 18, 21],\n",
    "            convex_list=[0],\n",
    "            verbose=True, val_ratio=0.2, random_state=0)\n",
    "model_fico.fit(train_x, train_y)\n",
    "data_dict_logs = model_fico.summary_logs(save_dict=False)\n",
    "plot_trajectory(data_dict_logs, folder=folder, name=\"fico_traj\", save_png=True, save_eps=True)\n",
    "plot_regularization(data_dict_logs, folder=folder, name=\"fico_regu\", save_png=True, save_eps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:28:22.468647Z",
     "start_time": "2021-10-14T12:26:59.748Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_train = model_fico.predict(train_x)\n",
    "pred_test = model_fico.predict(test_x)\n",
    "gaminet_stat = np.hstack([np.round(get_metric(train_y, pred_train),5),\n",
    "                      np.round(get_metric(test_y, pred_test),5)])\n",
    "print(gaminet_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:28:22.469460Z",
     "start_time": "2021-10-14T12:26:59.749Z"
    }
   },
   "outputs": [],
   "source": [
    "gaminet_stat = np.hstack([np.round(np.mean(train_y == (pred_train > 0.5)),5),\n",
    "                          np.round(np.mean(test_y == (pred_test > 0.5)),5)])\n",
    "print(gaminet_stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:28:22.470139Z",
     "start_time": "2021-10-14T12:26:59.753Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dict_global = model_fico.global_explain(save_dict=True, folder=folder, name=\"fico_global\")\n",
    "global_visualize_density(data_dict_global, folder=folder, name=\"fico_global\",  #11, 13, 19, 20\n",
    "                         main_effect_num=16, interaction_num=4, cols_per_row=4, save_png=True, save_eps=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:28:22.470747Z",
     "start_time": "2021-10-14T12:26:59.756Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_importance_visualize(data_dict_global)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpret the prediction of a test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:28:22.471394Z",
     "start_time": "2021-10-14T12:26:59.759Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dict_local = model_fico.local_explain(test_x[[0]], test_y[[0]], save_dict=False)\n",
    "local_visualize(data_dict_local[0], save_png=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "FicoHeloc.ipynb",
   "provenance": [
    {
     "file_id": "1kxmAukKbw2t6BLF4ZZ6RH2uZmGY170MK",
     "timestamp": 1598498903467
    }
   ]
  },
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
